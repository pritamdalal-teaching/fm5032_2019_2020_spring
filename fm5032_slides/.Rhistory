source('~/.active-rstudio-document', echo=TRUE)
\begin{align*}
p(x) = Pr(Y = 1 | X).
\end{align*}
\begin{align*}
\mathcal{l}
\end{align*}
\begin{align*}
\log\Bigg(\frac{p(x)}{1 - p(x)} \Bigg) &= \beta_0 + \beta_1 X_1 + \ldots + \beta_p X_p.
\end{align*}
install.packages("knitr")
install.packages("revealjs")
install.packages("tidyverse")
install.packages("tidyverse", dependencies = TRUE)
install.packages('rvest', dependencies = TRUE)
install.packages('xml2')
install.packages('xml2')
install.packages('rvest')
install.packages('tidyverse')
install.packages('tidyquant')
\begin{align*}
E\big(y - \hat{f}(x_0)\big)^2 & = \big[E(\hat{f}(x_0))-y\big]^2 + E\big[\hat{f}(x_0) - E(\hat{f}(x_0))]^2 + \text{Var}(\epsilon) \\
& =  \big[\text{Bias}\big(\hat{f}(x_0)\big)\big]^2 \,\,\, + \text{Var}\big(\hat{f}(x_0)\big) + \text{Var}(\epsilon).
\end{align*}
This equation provides a formal demonstration how expected MSE of an estimate $\hat{f}$ decomposes into *variance* and *bias*.
\begin{align*}
E\big(y - \hat{f}(x_0)\big)^2 & = \big[E(\hat{f}(x_0))-y\big]^2 + E\big[\hat{f}(x_0) - E(\hat{f}(x_0))]^2 + \text{Var}(\epsilon) \\
& =  \big[\text{Bias}\big(\hat{f}(x_0)\big)\big]^2 \,\,\, + \text{Var}\big(\hat{f}(x_0)\big) \,\,\,\,\,\,+ \text{Var}(\epsilon).
\end{align*}
\begin{align*}
\sum_{m = 1}^{M} \frac{|R_m|}{n}
\end{align*}
\begin{align*}
\sum_{m = 1}^{M} \frac{|R_m|}{n} (1 - \max_{k}(\hat{p}_{mk}))
\end{align*}
\begin{align*}
\text{Gini Index} &= \sum_{k=1}{K}\hat{p}_{mk}(1 -\hat{p}_{mk})
\end{align*}
\begin{align*}
\text{Gini Index} &= \sum_{k=1}^{K}\hat{p}_{mk}(1 -\hat{p}_{mk})
\end{align*}
\begin{align*}
\text{Gini Index} &= \sum_{k=1}^{K}\hat{p}_{mk}(1 -\hat{p}_{mk}) \\
For classifiction, the averaging can occur by plurality vote, or by taking an average of the probabilities.  The latter gives greater weight to confident predictions.
# Miscellaneous Notes
The idea is that if there is one very predictive, then all the bootstrapped trees will look very similar, and thus their predictions will be highly correlated, making the averaging less effective.
Both these measures lead to similar trees.  Gini-Index is a good default to start with, and is the default in `sklearn`.
