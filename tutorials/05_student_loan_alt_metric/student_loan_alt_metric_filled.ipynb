{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Loan Prepayments: Alternative Goodness-of-Fit Metric & Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we consider an alternative goodness-of-fit metrics for our student loan prepayment prediction problem.  These alternative metrics will be used in your student loan exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading the packages that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading-In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's read-in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_id</th>\n",
       "      <th>deal_name</th>\n",
       "      <th>loan_age</th>\n",
       "      <th>cosign</th>\n",
       "      <th>income_annual</th>\n",
       "      <th>upb</th>\n",
       "      <th>monthly_payment</th>\n",
       "      <th>fico</th>\n",
       "      <th>origbalance</th>\n",
       "      <th>mos_to_repay</th>\n",
       "      <th>repay_status</th>\n",
       "      <th>mos_to_balln</th>\n",
       "      <th>paid_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>765579</td>\n",
       "      <td>2014_b</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>113401.60</td>\n",
       "      <td>36011.11</td>\n",
       "      <td>397.91</td>\n",
       "      <td>814</td>\n",
       "      <td>51453.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>765580</td>\n",
       "      <td>2014_b</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>100742.34</td>\n",
       "      <td>101683.38</td>\n",
       "      <td>1172.10</td>\n",
       "      <td>711</td>\n",
       "      <td>130271.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>765581</td>\n",
       "      <td>2014_b</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>46000.24</td>\n",
       "      <td>49249.37</td>\n",
       "      <td>593.57</td>\n",
       "      <td>772</td>\n",
       "      <td>62918.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>765582</td>\n",
       "      <td>2014_b</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>428958.96</td>\n",
       "      <td>36554.85</td>\n",
       "      <td>404.63</td>\n",
       "      <td>849</td>\n",
       "      <td>48238.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>765583</td>\n",
       "      <td>2014_b</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>491649.96</td>\n",
       "      <td>7022.30</td>\n",
       "      <td>1967.46</td>\n",
       "      <td>815</td>\n",
       "      <td>106124.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043306</th>\n",
       "      <td>1808885</td>\n",
       "      <td>2019_c</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>152885.00</td>\n",
       "      <td>115363.12</td>\n",
       "      <td>1212.22</td>\n",
       "      <td>798</td>\n",
       "      <td>116834.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043307</th>\n",
       "      <td>1808886</td>\n",
       "      <td>2019_c</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>116480.00</td>\n",
       "      <td>77500.70</td>\n",
       "      <td>831.13</td>\n",
       "      <td>826</td>\n",
       "      <td>79566.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043308</th>\n",
       "      <td>1808887</td>\n",
       "      <td>2019_c</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>96800.00</td>\n",
       "      <td>16156.76</td>\n",
       "      <td>232.34</td>\n",
       "      <td>781</td>\n",
       "      <td>16472.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043309</th>\n",
       "      <td>1808888</td>\n",
       "      <td>2019_c</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>78400.14</td>\n",
       "      <td>77197.03</td>\n",
       "      <td>833.57</td>\n",
       "      <td>777</td>\n",
       "      <td>78135.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043310</th>\n",
       "      <td>1808889</td>\n",
       "      <td>2019_c</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>50447.28</td>\n",
       "      <td>65667.85</td>\n",
       "      <td>767.10</td>\n",
       "      <td>765</td>\n",
       "      <td>82602.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1043311 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         load_id deal_name  loan_age  cosign  income_annual        upb  \\\n",
       "0         765579    2014_b        56       0      113401.60   36011.11   \n",
       "1         765580    2014_b        56       1      100742.34  101683.38   \n",
       "2         765581    2014_b        56       0       46000.24   49249.37   \n",
       "3         765582    2014_b        56       0      428958.96   36554.85   \n",
       "4         765583    2014_b        56       0      491649.96    7022.30   \n",
       "...          ...       ...       ...     ...            ...        ...   \n",
       "1043306  1808885    2019_c         2       0      152885.00  115363.12   \n",
       "1043307  1808886    2019_c         2       0      116480.00   77500.70   \n",
       "1043308  1808887    2019_c         2       0       96800.00   16156.76   \n",
       "1043309  1808888    2019_c         2       0       78400.14   77197.03   \n",
       "1043310  1808889    2019_c        65       0       50447.28   65667.85   \n",
       "\n",
       "         monthly_payment  fico  origbalance  mos_to_repay  repay_status  \\\n",
       "0                 397.91   814     51453.60             0             0   \n",
       "1                1172.10   711    130271.33             0             0   \n",
       "2                 593.57   772     62918.96             0             0   \n",
       "3                 404.63   849     48238.73             0             0   \n",
       "4                1967.46   815    106124.68             0             0   \n",
       "...                  ...   ...          ...           ...           ...   \n",
       "1043306          1212.22   798    116834.64             0             0   \n",
       "1043307           831.13   826     79566.03             0             0   \n",
       "1043308           232.34   781     16472.50             0             0   \n",
       "1043309           833.57   777     78135.54             0             0   \n",
       "1043310           767.10   765     82602.38             0             0   \n",
       "\n",
       "         mos_to_balln  paid_label  \n",
       "0                 124           0  \n",
       "1                 124           0  \n",
       "2                 124           0  \n",
       "3                 125           0  \n",
       "4                   4           0  \n",
       "...               ...         ...  \n",
       "1043306           118           0  \n",
       "1043307           118           0  \n",
       "1043308            82           0  \n",
       "1043309           118           0  \n",
       "1043310           119           0  \n",
       "\n",
       "[1043311 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('student_loan.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the columns of our data set with the `DataFrame.info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1043311 entries, 0 to 1043310\n",
      "Data columns (total 13 columns):\n",
      "load_id            1043311 non-null int64\n",
      "deal_name          1043311 non-null object\n",
      "loan_age           1043311 non-null int64\n",
      "cosign             1043311 non-null int64\n",
      "income_annual      1043311 non-null float64\n",
      "upb                1043311 non-null float64\n",
      "monthly_payment    1043311 non-null float64\n",
      "fico               1043311 non-null int64\n",
      "origbalance        1043311 non-null float64\n",
      "mos_to_repay       1043311 non-null int64\n",
      "repay_status       1043311 non-null int64\n",
      "mos_to_balln       1043311 non-null int64\n",
      "paid_label         1043311 non-null int64\n",
      "dtypes: float64(4), int64(8), object(1)\n",
      "memory usage: 103.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing Our Features and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data in memory, we can separate the features and labels in preparation for model fitting.  We begin with the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_age</th>\n",
       "      <th>cosign</th>\n",
       "      <th>income_annual</th>\n",
       "      <th>upb</th>\n",
       "      <th>monthly_payment</th>\n",
       "      <th>fico</th>\n",
       "      <th>origbalance</th>\n",
       "      <th>mos_to_repay</th>\n",
       "      <th>repay_status</th>\n",
       "      <th>mos_to_balln</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>113401.60</td>\n",
       "      <td>36011.11</td>\n",
       "      <td>397.91</td>\n",
       "      <td>814</td>\n",
       "      <td>51453.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>100742.34</td>\n",
       "      <td>101683.38</td>\n",
       "      <td>1172.10</td>\n",
       "      <td>711</td>\n",
       "      <td>130271.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>46000.24</td>\n",
       "      <td>49249.37</td>\n",
       "      <td>593.57</td>\n",
       "      <td>772</td>\n",
       "      <td>62918.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>428958.96</td>\n",
       "      <td>36554.85</td>\n",
       "      <td>404.63</td>\n",
       "      <td>849</td>\n",
       "      <td>48238.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>491649.96</td>\n",
       "      <td>7022.30</td>\n",
       "      <td>1967.46</td>\n",
       "      <td>815</td>\n",
       "      <td>106124.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_age  cosign  income_annual        upb  monthly_payment  fico  \\\n",
       "0        56       0      113401.60   36011.11           397.91   814   \n",
       "1        56       1      100742.34  101683.38          1172.10   711   \n",
       "2        56       0       46000.24   49249.37           593.57   772   \n",
       "3        56       0      428958.96   36554.85           404.63   849   \n",
       "4        56       0      491649.96    7022.30          1967.46   815   \n",
       "\n",
       "   origbalance  mos_to_repay  repay_status  mos_to_balln  \n",
       "0     51453.60             0             0           124  \n",
       "1    130271.33             0             0           124  \n",
       "2     62918.96             0             0           124  \n",
       "3     48238.73             0             0           125  \n",
       "4    106124.68             0             0             4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_features = \\\n",
    "    ['loan_age','cosign','income_annual', 'upb',              \n",
    "    'monthly_payment','fico','origbalance',\n",
    "    'mos_to_repay','repay_status','mos_to_balln',]    \n",
    "df_X = df_train[lst_features]\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And next we do the same for the labels.  Note that in our encoding a `1` stands for prepayment, while a `0` stands for non-prepayment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "          ..\n",
       "1043306    0\n",
       "1043307    0\n",
       "1043308    0\n",
       "1043309    0\n",
       "1043310    0\n",
       "Name: paid_label, Length: 1043311, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = df_train['paid_label']\n",
    "df_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Holdout Set with `train_test_split()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In subsequent sections we will require a holdout set to measure the out-of-sample performance of our models, so let's create that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, random_state = 0, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Explore `X_train` and `X_test` and verify that the `test_size` parameter controls the size of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(938979, 10)\n",
      "(104332, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Accuracy, Precision, Reall, F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll review the traditional goodness-of-fit metrics:  accuracy, precision, recall, and F1.  We'll do this in the context of logistic regression.\n",
    "\n",
    "Let's begin by fitting a logistic regression to the entirety of our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pritamdalal/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "mdl_logit = LogisticRegression(random_state = 0)\n",
    "mdl_logit.fit(df_X, df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `predict()` method of our model to generate the predictions of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_pred_logit = mdl_logit.predict(df_X)\n",
    "arr_pred_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at various in-sample accuracy measures of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.984\n",
      "Precision:  0.012\n",
      "Recall:     0.329\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:  \", np.round(mdl_logit.score(df_X, df_y), 3))\n",
    "print(\"Precision: \", np.round(sklearn.metrics.precision_score(arr_pred_logit, df_y), 3))\n",
    "print(\"Recall:    \", np.round(sklearn.metrics.recall_score(arr_pred_logit, df_y), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Use the built-in function in `sklearn.metrics` to calculate the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023\n"
     ]
    }
   ],
   "source": [
    "print(np.round(sklearn.metrics.f1_score(arr_pred_logit, df_y), 3))\n",
    "      \n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, in-sample goodness-of-fit metrics are usually too optimistic about model performance.  Using a holdout test-set is a simple way to get a sense for how the model will perform in the wild.\n",
    "\n",
    "The following code fits a logistic regression model to the training set that we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pritamdalal/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_logit_holdout = LogisticRegression(random_state = 0)\n",
    "mdl_logit_holdout.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is code that calculated the out-of-sample goodness of fit metrics on the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.984\n",
      "Precision:  0.011\n",
      "Recall:     0.316\n",
      "F1:         0.021\n"
     ]
    }
   ],
   "source": [
    "arr_pred_logit_holdout = mdl_logit_holdout.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:  \", np.round(mdl_logit_holdout.score(X_test, y_test), 3))\n",
    "print(\"Precision: \", np.round(sklearn.metrics.precision_score(arr_pred_logit_holdout, y_test), 3))\n",
    "print(\"Recall:    \", np.round(sklearn.metrics.recall_score(arr_pred_logit_holdout, y_test), 3))\n",
    "print(\"F1:        \", np.round(sklearn.metrics.f1_score(arr_pred_logit_holdout, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balances of Loans that Actually Prepaid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far our all of our goodness-of-fit measures have focused on tallying the accuracy of individual predictions.  However, ABS investors are not interested in which particular loans prepayed, but rather the total UPB that prepayed.\n",
    "\n",
    "The following code calculates the total UPB of the loans that actually prepayed in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "683871848.0400001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbl_upb_prepay = \\\n",
    "    (\n",
    "    df_train[['upb', 'paid_label']]\n",
    "        .assign(prepay_upb = lambda df: df.upb * df.paid_label)\n",
    "        ['prepay_upb'].sum()\n",
    "    )\n",
    "dbl_upb_prepay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balances of Predicted Prepays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now calculate the balance of the loans that our logistic regression model predicts will prepay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28814002.620000005"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbl_upb_prepay_logit = \\\n",
    "    (\n",
    "    df_train\n",
    "        .assign(pred_logit = mdl_logit.predict(df_X))\n",
    "        .assign(prepay_upb_logit = lambda df: df.pred_logit * df.upb)\n",
    "        ['prepay_upb_logit'].sum()\n",
    "    )\n",
    "\n",
    "dbl_upb_prepay_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the logitstic regression UPB prepay predictions are only 4% of what actually occurred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04213362884081559"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbl_upb_prepay_logit / dbl_upb_prepay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Value of Total Balance of Loan Prepayment (In-Sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, most classification algorithms calculate a probability for each class.  The specific prediction is then simply the class with the highest probability.\n",
    "\n",
    "In `sklearn` we can view these probabilities with the `.predict_proba()` method.  Let's do this with `mdl_logit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99111785, 0.00888215],\n",
       "       [0.98603965, 0.01396035],\n",
       "       [0.98919476, 0.01080524],\n",
       "       ...,\n",
       "       [0.98582132, 0.01417868],\n",
       "       [0.99220591, 0.00779409],\n",
       "       [0.98780569, 0.01219431]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_logit.predict_proba(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, the probability of prepayment is in the second column, which we can isolate as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00888215, 0.01396035, 0.01080524, ..., 0.01417868, 0.00779409,\n",
       "       0.01219431])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_logit.predict_proba(df_X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these probabilities, let's calculate an expected value for the total UPB that will be prepaid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "683878025.8196985"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbl_ev_logit = \\\n",
    "    (\n",
    "    df_train\n",
    "        .assign(pred_logit = mdl_logit.predict_proba(df_X)[:,1])\n",
    "        .assign(prepay_upb_logit = lambda df: df.pred_logit * df.upb)\n",
    "        ['prepay_upb_logit'].sum()\n",
    "    )\n",
    "\n",
    "dbl_ev_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the in-sample expected value calculation is almost exactly in-line with the actual prepayments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000090335341572"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbl_ev_logit / dbl_upb_prepay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Value of Total Balance of Loan Prepayments (Out-of-Sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, from a UPB standpoint, our model seems to be working quite well.  However, the above calculation was done in-sample.  Let's try an out-of-sample accuracy measure calculation with our holdout set.\n",
    "\n",
    "We begin by fitting a model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pritamdalal/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_logit_holdout = LogisticRegression(random_state = 0)\n",
    "mdl_logit_holdout.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's calculated the actual prepayments in the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68602482.71000001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbl_prepay_test = \\\n",
    "    (\n",
    "    X_test\n",
    "        .merge(y_test, left_index=True, right_index = True)\n",
    "        .assign(upb_prepay = lambda df: df.upb * df.paid_label)\n",
    "        ['upb_prepay'].sum()    \n",
    "    )\n",
    "dbl_prepay_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code returns the out-of-sample prediction probabilities for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98707464, 0.01292536],\n",
       "       [0.99656728, 0.00343272],\n",
       "       [0.99585193, 0.00414807],\n",
       "       ...,\n",
       "       [0.98461229, 0.01538771],\n",
       "       [0.99116153, 0.00883847],\n",
       "       [0.97110025, 0.02889975]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_logit_holdout.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Calculate the out-of-sample expected value of prepaid UPB for the hold-out test set; also, find it's proportion relative to the actual prepayments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835755083848126"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbl_prepay_holdout = \\\n",
    "    (\n",
    "    X_test\n",
    "        .assign(pred_holdout = mdl_logit_holdout.predict_proba(X_test)[:, 1])\n",
    "        .assign(upb_prepay_holdout = lambda df: df.upb * df.pred_holdout)\n",
    "        ['upb_prepay_holdout'].sum()\n",
    "    )\n",
    "\n",
    "dbl_prepay_holdout / dbl_prepay_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation for Precision, Recall, and F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The holdout set methodology can be generalized to $n$-fold cross validation.  The set of goodness-of-fit measures that result from cross-validation are, in aggregate, more robust than a metric calculated on a single holdout test set.  \n",
    "\n",
    "In this final section, we'll see what the code looks like to generate these cross-validation metrics for a decision tree classifier.\n",
    "\n",
    "Let's begin by instantiating a decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "mdl_tree = DecisionTreeClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code generates F1, precision, and recall via cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([13.56170487, 13.5207057 , 11.84063768, 12.0791862 , 11.92676163]),\n",
       " 'score_time': array([0.26099586, 0.27190232, 0.26139569, 0.26395988, 0.2576015 ]),\n",
       " 'test_f1': array([0.22146021, 0.35640309, 0.37034759, 0.38759257, 0.41711533]),\n",
       " 'test_precision': array([0.21438451, 0.40163023, 0.38602116, 0.36751457, 0.40054422]),\n",
       " 'test_recall': array([0.22901891, 0.32033097, 0.35589713, 0.40999113, 0.43511676])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_cv = sklearn.model_selection.cross_validate(mdl_tree, df_X, df_y, scoring = ['f1', 'precision', 'recall'], cv = 5)\n",
    "dct_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Calculate the average F1 score in our cross-validation scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35058375627592636"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_cv['test_f1'].mean()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goodness of fit metric that will be most useful to us will be the expected value of prepayed balance.  Unfortunately, this does not fit neatly into the `.cross_validate()` method in the previous section.  Thus, in order to use our expected value of prepayed balance metric in a cross-validation context, we will have to write some of the boiler-plate code that `sklearn.model_selection` takes care of for us. We will do this next time.\n",
    "\n",
    "Once that's done, you will have enough tools to work on the Student Loan assignment, which will involve hyperparameter tuning of the various classification models we have used thus far.  We will use two metrics for the basis of selecting optimal hyperparameters:\n",
    "\n",
    "1. 10-fold CV Expected UPB Prepayed\n",
    "2. 10-fold CV F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sklearn User Guides**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "\n",
    "**Sklearn API Documentation**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
