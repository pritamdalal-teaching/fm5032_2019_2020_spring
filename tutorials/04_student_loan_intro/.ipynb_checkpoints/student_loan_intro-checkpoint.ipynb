{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Student Loan Prepayments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asset-backed Securities (ABS) are fixed income instruments that securitize the cashflows from various kinds of loans such as auto-loans, credit card balances, and students loans.  Many of the loans backing ABS have fixed payment schedules that fully amortize the loan amount.  However, they usually also give the borrower the option to repay larger amounts (up to the full loan balance) at any time without penalty, which is referred to as prepayment.  For a given ABS, the rate at which the underlying loans prepay affects the timing of principle repayments as well as the amount of interest that the ABS owner earns.  Thus, predicting prepayment speeds is of interest to ABS investors.\n",
    "\n",
    "In this tutorial we make our first attempt at predicting student loan prepayments.  Our focus will be on familiarizing ourselves with the data and getting some initial models fit with `sklearn`. We will dig into the details of these models in later tutorials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading the packages that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> import pandas as pd\n",
    "##> import numpy as np\n",
    "##> import sklearn\n",
    "##> pd.options.display.max_rows = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading-In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's read-in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_train = pd.read_csv('student_loan.csv')\n",
    "##> df_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the columns of our data set with the `DataFrame.info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_train.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing Our Features and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data in memory, we can separate the features and labels in preparation for model fitting.  We begin with the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> lst_features = \\\n",
    "##>     ['loan_age','cosign','income_annual', 'upb',              \n",
    "##>     'monthly_payment','fico','origbalance',\n",
    "##>     'mos_to_repay','repay_status','mos_to_balln',]    \n",
    "##> df_X = df_train[lst_features]\n",
    "##> df_X\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And next we do the same for the labels.  Note that in our encoding a `1` stands for prepayment, while a `0` stands for non-prepayment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_y = df_train['paid_label']\n",
    "##> df_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first classification model that we fit is called *logistic regression* (the name is a poor choice of words because despite being called a regression, it is actually used for classification).  Although logistic regression can be used to predict a label with more than two outcomes, it is most effective when used to predict binary outcomes.\n",
    "\n",
    "As with any modeling task, we begin by importing the constructor function for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> mdl_logit = LogisticRegression(random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go ahead and fit our model, which will take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> mdl_logit.fit(df_X, df_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how well does our model predict the training data?  The standard metric for determining goodness of fit in a classification setting is *accuracy*, which is simply the the ratio of correct predictions to total predictions.  This is the default metric that is used by the `.score()` method of classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> mdl_logit.score(df_X, df_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Question:** This accuracy looks great.  So is our work done?  Why might this accuracy be misleading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:**  Calculate the probability of prepayment in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the code challenge, our student loan data is highly imbalanced, meaning there are far more loans that don't prepay than those that do prepay.  Predicting rare outcomes via classification can be challenging.  We will address the imbalance issue in future lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful consider other metrics when performing classification.  In order to invoke these methods, we will need to be able to grab the predictions from our model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> mdl_logit.predict(df_X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Calculate the probability of prepayment as predicted by our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative goodness of fit metric is called *precision*, which is the percentage of prepayment predictions that were correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> sklearn.metrics.precision_score(mdl_logit.predict(df_X), df_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another metric that we will consider is *recall*, which is the percentage of actual prepayments that were predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> sklearn.metrics.recall_score(mdl_logit.predict(df_X), df_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing classification, we strive for a model that has both high precision and high recall.  Thus, it makes sense to combine these two metric into a single metric.  The standard combined metric that is used is called *F1* and is defined as follows:\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "The following code calculates F1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> precision = sklearn.metrics.precision_score(mdl_logit.predict(df_X), df_y)\n",
    "##> recall = sklearn.metrics.recall_score(mdl_logit.predict(df_X), df_y)\n",
    "##> \n",
    "##> 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sklearn` has F1 built into the the `metrics` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> sklearn.metrics.f1_score(mdl_logit.predict(df_X), df_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model we are going to fit to our student loan data is a *decision tree* classifier.  As with any model, our initial steps are as follows:\n",
    "\n",
    "1. import the constructor\n",
    "1. instantiate the model\n",
    "1. fit model to data\n",
    "\n",
    "Let's do all three steps in the next code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> from sklearn.tree import DecisionTreeClassifier\n",
    "##> mdl_tree = DecisionTreeClassifier(random_state = 0)\n",
    "##> mdl_tree.fit(df_X, df_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Calculate the accuracy and F1 for our fitted decision tree model.  Can we pat ourselves on the back and call it quits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees often overfit the data, which is what we are observing in code challenge above.  Thus, while `mdl_tree` looks great with the training data, it won't look nearly so good in the wild.  One way to get a sense for this is to use a holdout set, which can conveniently do with the `train_test_split()` function in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(df_X, df_y, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate a new decision tree model and fit it to only `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> mdl_holdout = DecisionTreeClassifier(random_state = 0)\n",
    "##> mdl_holdout.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see how our hold out model performs on the test data `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> sklearn.metrics.f1_score(mdl_holdout.predict(X_test), y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the by  products of the fitting decision tree is that it assigns an importance to the features.  This can be accessed with the `feature_importances_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> mdl_tree.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this output more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> dct_cols = {'feature':df_X.columns.values, 'importance':mdl_tree.feature_importances_}\n",
    "##> pd.DataFrame(dct_cols).sort_values('importance', ascending = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final classifier we will consider is a *random forest*.  A random forest is gotten by fitting several decision trees to random subsets of the features, and then averaging the results.  Random forest are *ensemble* methods, meaning they aggregate the results of a number of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we begin by instantiating and fitting the model.  The `n_estimators` input controls the number of sub-decision-trees that are aggregated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> from sklearn.ensemble import RandomForestClassifier\n",
    "##> mdl_forest = RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "##> mdl_forest.fit(df_X, df_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the in-sample F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> sklearn.metrics.f1_score(mdl_forest.predict(df_X), df_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's fit our model to the holdout training set that we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> mdl_holdout_forest = RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "##> mdl_holdout_forest.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finall, let's check the F1 score on our holdout test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> sklearn.metrics.f1_score(mdl_holdout_forest.predict(X_test), y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sklearn User Guides**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees\n",
    "\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "\n",
    "**Sklearn API Documentation**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
